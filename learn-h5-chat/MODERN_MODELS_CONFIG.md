# ç°ä»£AIæ¨¡å‹é…ç½®æŒ‡å—

> æœ¬æŒ‡å—æä¾›2024-2025å¹´æœ€æ–°AIæ¨¡å‹çš„æ¥å…¥æ–¹å¼å’Œé…ç½®

## ğŸ“Š æ¨¡å‹ç”Ÿæ€å…¨æ™¯

### é¡¶çº§æ¨ç†æ¨¡å‹ï¼ˆæ¨èç”¨äºå¤æ‚é—®é¢˜ï¼‰

#### 1. GPT-4o (OpenAI) - 2024/11å‘å¸ƒ

**ç‰¹ç‚¹**ï¼šå¤šæ¨¡æ€ã€æœ€å¿«ã€æœ€å…¨èƒ½

```typescript
const config = {
  provider: 'openai',
  baseUrl: 'https://api.openai.com/v1',
  modelId: 'gpt-4o',  // æœ€æ–°çš„é€šç”¨æ¨¡å‹
  apiKey: process.env.OPENAI_API_KEY
}

// ä½¿ç”¨ç¤ºä¾‹
await callAI('ä»Šå¤©å¤©æ°”å¦‚ä½•?', config)
```

**å®šä»·**ï¼š$5/$15 per 1M tokens  
**ä¸Šä¸‹æ–‡**ï¼š128K tokens  
**ç‰¹è‰²**ï¼šæœ€æ–°è§†è§‰èƒ½åŠ›ã€æœ€å¿«å“åº”

---

#### 2. Gemini 2.5 Pro (Google) - 2025/01å‘å¸ƒ

**ç‰¹ç‚¹**ï¼šç™¾ä¸‡tokenä¸Šä¸‹æ–‡ã€æ€è€ƒé¢„ç®—ã€æˆæœ¬ä½

```typescript
const config = {
  provider: 'gemini',
  modelId: 'gemini-2.5-pro',
  apiKey: process.env.GEMINI_API_KEY
}

// ä½¿ç”¨æ€è€ƒé¢„ç®—ï¼ˆæ·±åº¦æ¨ç†ï¼‰
const response = await generateResponse(
  prompt,
  'gemini-2.5-pro',
  false,
  undefined,
  undefined,
  undefined,
  undefined,
  { thinkingBudget: 24576 } // å¯ç”¨æ·±åº¦æ€è€ƒ
)
```

**å®šä»·**ï¼š$1.25/$2.5 per 1M tokens  
**ä¸Šä¸‹æ–‡**ï¼š1M tokensï¼ˆæœ€é•¿ï¼‰  
**ç‰¹è‰²**ï¼šæ€è€ƒé¢„ç®—ã€æ€§ä»·æ¯”æœ€ä¼˜

---

#### 3. Claude 3.5 Sonnet (Anthropic) - 2024/10å‘å¸ƒ

**ç‰¹ç‚¹**ï¼šæ¨ç†å¼ºã€å®‰å…¨æ€§å¥½ã€ç¼–ç èƒ½åŠ›é¡¶çº§

```typescript
// éœ€è¦å®‰è£… @anthropic-ai/sdk
import Anthropic from '@anthropic-ai/sdk'

const client = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY
})

const response = await client.messages.create({
  model: 'claude-3-5-sonnet-20241022',
  max_tokens: 1024,
  messages: [
    { role: 'user', content: 'å†™ä¸€ä¸ªReactç»„ä»¶' }
  ]
})
```

**å®šä»·**ï¼š$3/$15 per 1M tokens  
**ä¸Šä¸‹æ–‡**ï¼š200K tokens  
**ç‰¹è‰²**ï¼šç¼–ç æœ€å¼ºã€æ¨ç†ä¸¥è°¨

---

### å¹³è¡¡æ¨¡å‹ï¼ˆæ€§ä»·æ¯”æœ€ä¼˜ï¼‰

#### 4. Gemini 2.5 Flash (Google)

**æœ€å¿«é€Ÿã€æœ€ç»æµçš„é€‰æ‹©**

```typescript
const config = {
  modelId: 'gemini-2.5-flash',
  provider: 'gemini'
}

// å®æ—¶åº”ç”¨ã€èŠå¤©æœºå™¨äººçš„é¦–é€‰
```

**å®šä»·**ï¼š$0.075/$0.30 per 1M tokens  
**ä¼˜åŠ¿**ï¼šè¶…å¿«ã€æä¾¿å®œã€ä»ç„¶èªæ…§

---

#### 5. GPT-4o mini (OpenAI)

**è½»é‡çº§ä½†èªæ…§çš„é€‰æ‹©**

```typescript
const config = {
  modelId: 'gpt-4o-mini',
  provider: 'openai'
}

// æœ€é€‚åˆé‡å¤§ã€å¯¹æˆæœ¬æ•æ„Ÿçš„åº”ç”¨
```

**å®šä»·**ï¼š$0.15/$0.60 per 1M tokens  
**ä¼˜åŠ¿**ï¼šæˆæœ¬ä½ã€é€Ÿåº¦å¿«ã€è¶³å¤Ÿèªæ…§

---

### æœ¬åœ°éƒ¨ç½²æ¨¡å‹ï¼ˆå¼€æºã€å…è´¹ï¼‰

#### 6. Llama 3.1 (Meta) - é€šè¿‡Ollama

**å®Œå…¨å…è´¹ã€å¯ç¦»çº¿è¿è¡Œ**

```bash
# å®‰è£…Ollama
# https://ollama.ai

# å¯åŠ¨æœåŠ¡
ollama serve

# ä¸‹è½½æ¨¡å‹ï¼ˆæ¨èï¼‰
ollama pull llama3.1:70b  # æœ€å¥½çš„æ¨ç†èƒ½åŠ›
ollama pull llama3.1      # æ›´å°çš„ç‰ˆæœ¬
```

```typescript
const config = {
  provider: 'openai', // Ollamaå…¼å®¹OpenAI APIæ ¼å¼
  baseUrl: 'http://localhost:11434/v1',
  modelId: 'llama3.1',
  apiKey: '' // Ollamaä¸éœ€è¦å¯†é’¥
}

await callAI('ä½ å¥½', config)
```

**æˆæœ¬**ï¼šå…è´¹ï¼ˆè‡ªæ‰˜ç®¡ï¼‰  
**ä¼˜åŠ¿**ï¼šå®Œå…¨éšç§ã€ç¦»çº¿å¯ç”¨ã€æ— APIé™åˆ¶

---

#### 7. Mistral Large (Mistral AI) - é€šè¿‡Together.aiæˆ–è‡ªæ‰˜ç®¡

**æ¬§æ´²é¡¶çº§å¼€æºæ¨¡å‹**

```typescript
// æ–¹å¼1ï¼šé€šè¿‡Together.ai API
const config = {
  provider: 'openai',
  baseUrl: 'https://api.together.xyz/v1',
  modelId: 'mistralai/Mistral-7B-Instruct-v0.1',
  apiKey: process.env.TOGETHER_API_KEY
}

// æ–¹å¼2ï¼šæœ¬åœ°Ollama
const localConfig = {
  provider: 'openai',
  baseUrl: 'http://localhost:11434/v1',
  modelId: 'mistral'
}
```

---

## ğŸ”§ é…ç½®å¯¹æ¯”è¡¨

### æŒ‰ä½¿ç”¨åœºæ™¯é€‰æ‹©

| åœºæ™¯ | æ¨èæ¨¡å‹ | ç†ç”± |
|------|---------|------|
| **ç®€å•Q&A** | gpt-4o-mini | æœ€ä¾¿å®œã€è¶³å¤Ÿèªæ…§ |
| **å¤æ‚æ¨ç†** | gemini-2.5-pro | æ€è€ƒé¢„ç®—ã€ä¸Šä¸‹æ–‡é•¿ |
| **ç¼–ç åŠ©æ‰‹** | claude-3.5-sonnet | ä»£ç èƒ½åŠ›æœ€å¼º |
| **å®æ—¶èŠå¤©** | gemini-2.5-flash | æœ€å¿«ã€æœ€ä¾¿å®œ |
| **é•¿æ–‡æ¡£å¤„ç†** | gemini-2.5-pro | ç™¾ä¸‡tokenä¸Šä¸‹æ–‡ |
| **æœ¬åœ°éƒ¨ç½²** | llama3.1 | å®Œå…¨å¼€æºã€æ— æˆæœ¬ |
| **æˆæœ¬æœ€ä¼˜** | gpt-4o-mini | $0.15/$0.60 |
| **æœ€æ–°èƒ½åŠ›** | gpt-4o | æœ€å…¨èƒ½ |

---

## ğŸ“ é€æ­¥æ¥å…¥æŒ‡å—

### Step 1: é€‰æ‹©æä¾›å•†

```typescript
// å¿«é€Ÿå†³ç­–æ ‘
function chooseProvider(requirements: {
  budget: 'free' | 'low' | 'medium' | 'high'
  latency: 'critical' | 'normal' | 'flexible'
  complexity: 'simple' | 'medium' | 'complex'
  privacy: 'public' | 'private'
}): string {
  if (requirements.privacy === 'private') return 'ollama'
  if (requirements.budget === 'free') return 'ollama'
  
  if (requirements.latency === 'critical') return 'gpt-4o-mini'
  if (requirements.complexity === 'complex') return 'gemini-2.5-pro'
  
  return 'gpt-4o-mini' // é»˜è®¤é€‰æ‹©
}
```

---

### Step 2: è·å–APIå¯†é’¥

#### OpenAI
```bash
# 1. è®¿é—® https://platform.openai.com/api-keys
# 2. ç‚¹å‡» "Create new secret key"
# 3. å¤åˆ¶å¯†é’¥
# 4. ä¿å­˜åˆ° .env.local
OPENAI_API_KEY=sk-proj-xxxxx
```

#### Google Gemini
```bash
# 1. è®¿é—® https://aistudio.google.com/app/apikey
# 2. ç‚¹å‡» "Create API Key"
# 3. å¤åˆ¶å¯†é’¥
GEMINI_API_KEY=xxxx
```

#### Anthropic Claude
```bash
# 1. è®¿é—® https://console.anthropic.com/
# 2. åˆ›å»ºAPIå¯†é’¥
ANTHROPIC_API_KEY=sk-ant-xxxxx
```

#### Together.ai (ç”¨äºMistralã€Llamaç­‰)
```bash
# 1. è®¿é—® https://www.together.ai/
# 2. åˆ›å»ºè´¦æˆ·å¹¶ç”ŸæˆAPIå¯†é’¥
TOGETHER_API_KEY=xxxx
```

---

### Step 3: åœ¨ä½ çš„é¡¹ç›®ä¸­ä½¿ç”¨

#### ç®€å•èŠå¤©åº”ç”¨

```typescript
// src/services/aiService.ts

export type ProviderType = 'openai' | 'gemini' | 'claude' | 'together' | 'ollama'

export interface AIConfig {
  provider: ProviderType
  apiKey?: string
  baseUrl?: string
  modelId: string
}

export async function chat(
  message: string,
  config: AIConfig
): Promise<string> {
  switch (config.provider) {
    case 'openai':
    case 'together':
    case 'ollama':
      return callOpenAICompatible(message, config)
    case 'gemini':
      return callGemini(message, config)
    case 'claude':
      return callClaude(message, config)
    default:
      throw new Error(`Unsupported provider: ${config.provider}`)
  }
}

async function callOpenAICompatible(
  message: string,
  config: AIConfig
): Promise<string> {
  const response = await fetch(
    `${config.baseUrl || 'https://api.openai.com/v1'}/chat/completions`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...(config.apiKey && { 'Authorization': `Bearer ${config.apiKey}` })
      },
      body: JSON.stringify({
        model: config.modelId,
        messages: [{ role: 'user', content: message }],
        temperature: 0.7,
        max_tokens: 1000
      })
    }
  )

  const data = await response.json()
  return data.choices[0].message.content
}

async function callGemini(
  message: string,
  config: AIConfig
): Promise<string> {
  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/${config.modelId}:generateContent?key=${config.apiKey}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents: [{ parts: [{ text: message }] }]
      })
    }
  )

  const data = await response.json()
  return data.candidates[0].content.parts[0].text
}

async function callClaude(
  message: string,
  config: AIConfig
): Promise<string> {
  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': config.apiKey || '',
      'anthropic-version': '2023-06-01'
    },
    body: JSON.stringify({
      model: config.modelId,
      max_tokens: 1024,
      messages: [{ role: 'user', content: message }]
    })
  })

  const data = await response.json()
  return data.content[0].text
}
```

#### åœ¨Reactç»„ä»¶ä¸­ä½¿ç”¨

```typescript
// src/components/ChatBox.tsx

import { useState } from 'react'
import { chat, AIConfig } from '../services/aiService'

const presets: Record<string, AIConfig> = {
  'gpt4o': {
    provider: 'openai',
    modelId: 'gpt-4o',
    apiKey: process.env.REACT_APP_OPENAI_KEY
  },
  'gpt4o-mini': {
    provider: 'openai',
    modelId: 'gpt-4o-mini',
    apiKey: process.env.REACT_APP_OPENAI_KEY
  },
  'gemini-pro': {
    provider: 'gemini',
    modelId: 'gemini-2.5-pro',
    apiKey: process.env.REACT_APP_GEMINI_KEY
  },
  'gemini-flash': {
    provider: 'gemini',
    modelId: 'gemini-2.5-flash',
    apiKey: process.env.REACT_APP_GEMINI_KEY
  },
  'claude-sonnet': {
    provider: 'claude',
    modelId: 'claude-3-5-sonnet-20241022',
    apiKey: process.env.REACT_APP_CLAUDE_KEY
  },
  'ollama-llama': {
    provider: 'ollama',
    modelId: 'llama3.1',
    baseUrl: 'http://localhost:11434/v1'
  }
}

export function ChatBox() {
  const [input, setInput] = useState('')
  const [output, setOutput] = useState('')
  const [selectedPreset, setSelectedPreset] = useState('gpt4o-mini')
  const [loading, setLoading] = useState(false)

  async function handleSend() {
    if (!input.trim()) return

    setLoading(true)
    try {
      const response = await chat(input, presets[selectedPreset])
      setOutput(response)
    } catch (error) {
      setOutput(`é”™è¯¯: ${error.message}`)
    } finally {
      setLoading(false)
    }
  }

  return (
    <div className="space-y-4 p-4">
      <div>
        <label className="block text-sm font-medium mb-2">é€‰æ‹©æ¨¡å‹</label>
        <select
          value={selectedPreset}
          onChange={(e) => setSelectedPreset(e.target.value)}
          className="w-full p-2 border rounded"
        >
          <option value="gpt4o">GPT-4o (å¿«é€Ÿã€å…¨èƒ½)</option>
          <option value="gpt4o-mini">GPT-4o mini (ä¾¿å®œ)</option>
          <option value="gemini-pro">Gemini 2.5 Pro (èªæ…§)</option>
          <option value="gemini-flash">Gemini 2.5 Flash (æœ€å¿«)</option>
          <option value="claude-sonnet">Claude 3.5 Sonnet (ç¼–ç )</option>
          <option value="ollama-llama">æœ¬åœ°Llama3.1 (å…è´¹)</option>
        </select>
      </div>

      <textarea
        value={input}
        onChange={(e) => setInput(e.target.value)}
        placeholder="è¾“å…¥ä½ çš„é—®é¢˜..."
        className="w-full p-3 border rounded min-h-24"
      />

      <button
        onClick={handleSend}
        disabled={loading}
        className="w-full px-4 py-2 bg-blue-500 text-white rounded disabled:opacity-50"
      >
        {loading ? 'å¤„ç†ä¸­...' : 'å‘é€'}
      </button>

      {output && (
        <div className="p-4 bg-gray-100 rounded">
          <h3 className="font-bold mb-2">å“åº”:</h3>
          <p className="whitespace-pre-wrap">{output}</p>
        </div>
      )}
    </div>
  )
}
```

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨ä¸‰å¤§æ–¹æ¡ˆ

### æ–¹æ¡ˆAï¼šåªç”¨OpenAIï¼ˆæœ€ç®€å•ï¼‰

```bash
# 1. è·å–APIå¯†é’¥ï¼šhttps://platform.openai.com/api-keys
# 2. è®¾ç½®ç¯å¢ƒå˜é‡
echo 'REACT_APP_OPENAI_KEY=sk-proj-xxxxx' > .env.local

# 3. ä½¿ç”¨
const response = await chat('ä½ å¥½', {
  provider: 'openai',
  modelId: 'gpt-4o-mini',
  apiKey: process.env.REACT_APP_OPENAI_KEY
})
```

### æ–¹æ¡ˆBï¼šæ··åˆä½¿ç”¨å¤šä¸ªæä¾›å•†ï¼ˆæ¨èï¼‰

```bash
# 1. è·å–å¤šä¸ªå¯†é’¥
REACT_APP_OPENAI_KEY=sk-proj-xxxxx
REACT_APP_GEMINI_KEY=xxxxx
REACT_APP_TOGETHER_KEY=xxxxx

# 2. æ ¹æ®éœ€æ±‚é€‰æ‹©æä¾›å•†
// ä¾¿å®œçš„ï¼šgpt-4o-mini
// å¿«çš„ï¼šgemini-2.5-flash
// èªæ…§çš„ï¼šgemini-2.5-pro
```

### æ–¹æ¡ˆCï¼šæœ¬åœ°éƒ¨ç½²ï¼ˆå®Œå…¨å…è´¹ï¼‰

```bash
# 1. å®‰è£…Ollamaï¼šhttps://ollama.ai
# 2. å¯åŠ¨æœåŠ¡
ollama serve

# 3. æ‹‰å–æ¨¡å‹
ollama pull llama3.1

# 4. ä½¿ç”¨
const response = await chat('ä½ å¥½', {
  provider: 'ollama',
  modelId: 'llama3.1',
  baseUrl: 'http://localhost:11434/v1'
})
```

---

## ğŸ“Š æˆæœ¬ä¼°ç®—å·¥å…·

```typescript
interface ModelPricing {
  inputCost: number    // æ¯ç™¾ä¸‡tokens
  outputCost: number   // æ¯ç™¾ä¸‡tokens
}

const pricing: Record<string, ModelPricing> = {
  'gpt-4o': { inputCost: 5, outputCost: 15 },
  'gpt-4o-mini': { inputCost: 0.15, outputCost: 0.60 },
  'gemini-2.5-pro': { inputCost: 1.25, outputCost: 2.5 },
  'gemini-2.5-flash': { inputCost: 0.075, outputCost: 0.30 },
  'claude-3.5-sonnet': { inputCost: 3, outputCost: 15 },
  'llama3.1': { inputCost: 0, outputCost: 0 }
}

function estimateCost(
  inputTokens: number,
  outputTokens: number,
  modelId: string
): number {
  const rate = pricing[modelId] || { inputCost: 1, outputCost: 1 }
  return (inputTokens * rate.inputCost + outputTokens * rate.outputCost) / 1_000_000
}

// ç¤ºä¾‹ï¼š1000ä¸ªè¾“å…¥token + 500ä¸ªè¾“å‡ºtoken
console.log(estimateCost(1000, 500, 'gpt-4o-mini'))         // $0.000000
console.log(estimateCost(1000, 500, 'gemini-2.5-flash'))    // $0.000225
console.log(estimateCost(1000, 500, 'gpt-4o'))              // $0.000008
console.log(estimateCost(1000, 500, 'llama3.1'))            // $0.000000
```

---

## ğŸŒ å¤šæ¨¡å‹åº”ç”¨ç¤ºä¾‹

```typescript
// src/services/multiProviderService.ts

interface ConversationMessage {
  role: 'user' | 'assistant'
  content: string
  model?: string
}

export class MultiProviderChat {
  private history: ConversationMessage[] = []

  async addMessage(
    userMessage: string,
    modelId: string = 'gpt-4o-mini'
  ): Promise<string> {
    this.history.push({ role: 'user', content: userMessage, model: modelId })

    // è·å–ä¸åŒæ¨¡å‹çš„å“åº”å¹¶æ¯”è¾ƒ
    const [response1, response2] = await Promise.all([
      chat(userMessage, { provider: 'openai', modelId: 'gpt-4o-mini' }),
      chat(userMessage, { provider: 'gemini', modelId: 'gemini-2.5-flash' })
    ])

    this.history.push({ role: 'assistant', content: response1, model: 'gpt-4o-mini' })

    return response1
  }

  getHistory(): ConversationMessage[] {
    return this.history
  }

  clear() {
    this.history = []
  }
}
```

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼šAPIå¯†é’¥æ— æ•ˆ

```typescript
// æ£€æŸ¥å¯†é’¥
async function validateAPIKey(key: string, provider: string): Promise<boolean> {
  try {
    const response = await fetch(`${getEndpoint(provider)}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${key}`
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [{ role: 'user', content: 'test' }],
        max_tokens: 1
      })
    })
    return response.ok
  } catch {
    return false
  }
}
```

### é—®é¢˜2ï¼šæ¨¡å‹ä¸å­˜åœ¨

```typescript
// åˆ—å‡ºå¯ç”¨æ¨¡å‹
async function listAvailableModels(provider: string): Promise<string[]> {
  const response = await fetch(`${getEndpoint(provider)}/models`, {
    headers: { 'Authorization': `Bearer ${getApiKey(provider)}` }
  })
  const data = await response.json()
  return data.data.map((m: any) => m.id)
}
```

### é—®é¢˜3ï¼šè¶…æ—¶

```typescript
// æ·»åŠ è¶…æ—¶æ§åˆ¶
async function chatWithTimeout(
  message: string,
  config: AIConfig,
  timeoutMs = 30000
): Promise<string> {
  return Promise.race([
    chat(message, config),
    new Promise<string>((_, reject) =>
      setTimeout(() => reject(new Error('API call timeout')), timeoutMs)
    )
  ])
}
```

---

## ğŸ“š å®Œæ•´æ¨¡å‹åˆ—è¡¨ï¼ˆ2024-2025ï¼‰

### OpenAIç³»
- `gpt-4-turbo` - ä¸Šä¸€ä»£æ——èˆ°
- `gpt-4o` - æœ€æ–°å…¨èƒ½
- `gpt-4o-mini` - è½»é‡çº§
- `gpt-3.5-turbo` - å…¥é—¨çº§

### Googleç³»
- `gemini-2.5-pro` - æ–°ä¸€ä»£æ——èˆ°
- `gemini-2.5-flash` - æ€§ä»·æ¯”ä¹‹ç‹
- `gemini-2.5-flash-lite` - è¶…è½»é‡
- `gemini-2.0-flash` - ç¨³å®šç‰ˆæœ¬

### Anthropicç³»
- `claude-3-5-sonnet-20241022` - æœ€æ–°
- `claude-3-opus` - æœ€å¼ºæ¨ç†
- `claude-3-haiku` - è½»é‡çº§

### å¼€æºç³»ï¼ˆOllama/Togetherï¼‰
- `llama3.1` - Metaæœ€æ–°
- `llama3.0` - ç¨³å®šç‰ˆæœ¬
- `mistral` - æ¬§æ´²ä¹‹æ˜Ÿ
- `neural-chat` - è½»é‡å¯¹è¯

---

**ç°åœ¨å°±é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ï¼Œå¼€å§‹ä½ çš„AIåº”ç”¨å¼€å‘å§ï¼** ğŸš€
